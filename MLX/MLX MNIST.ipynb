{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The idea behind this notebook is to  explore Apple's MLX library and see how it performs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from functools import partial\n",
    "\n",
    "import mlx.core as mx\n",
    "import mlx.nn as nn\n",
    "import mlx.optimizers as optim\n",
    "import numpy as np\n",
    "import mnist\n",
    "\n",
    "# Torch is still required to load and process the data\n",
    "import torchvision\n",
    "import torch\n",
    "import numpy as np\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We load the data just like a standard notebook: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(dataset = \"mnist\", \n",
    "              path = 'data', \n",
    "              train = True, \n",
    "              batch_size = 256, \n",
    "              transforms = torchvision.transforms.ToTensor(),\n",
    "              download  = True):\n",
    "    '''\n",
    "    Returns the dataset and dataloader for the specified dataset.\n",
    "    \n",
    "    Supported datasets: [mnist, cifar, fashion, emnist, kmnist, svhn]\n",
    "    '''\n",
    "    if dataset.lower() == 'mnist':\n",
    "        dataset = torchvision.datasets.MNIST(path, train=train, transform=transforms, download=download)\n",
    "    elif dataset.lower() == 'fashion':\n",
    "        dataset = torchvision.datasets.FashionMNIST(path, train=train, transform=transforms, download=download)\n",
    "    elif dataset.lower() == 'cifar':\n",
    "        dataset = torchvision.datasets.CIFAR10(path, train=train, transform=transforms, download=download)\n",
    "    elif dataset.lower() == 'emnist':\n",
    "        dataset = torchvision.datasets.EMNIST(path, train=train, transform=transforms, download=download, split='letters')\n",
    "    elif dataset.lower() == 'kmnist':\n",
    "        dataset = torchvision.datasets.KMNIST(path, train=train, transform=transforms, download=download)\n",
    "    elif dataset.lower() == 'svhn':\n",
    "        dataset = torchvision.datasets.SVHN(path + '/SVHN', split='train' if train else 'test', transform=transforms, download=download)\n",
    "    else:\n",
    "        raise ValueError('Invalid dataset. Options: [mnist, cifar, fashion, emnist, kmnist, svhn]')\n",
    "    loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "    return dataset, loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.fc1 = nn.Linear(784, 512)\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.fc3 = nn.Linear(256, 64)\n",
    "        self.out = nn.Linear(64, 10)\n",
    "    \n",
    "    def __call__(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = nn.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = nn.relu(x)\n",
    "        x = self.fc3(x)\n",
    "        x = nn.relu(x)\n",
    "        x = self.out(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_iterate(batch_size, X, y):\n",
    "    perm = mx.array(np.random.permutation(y.size))\n",
    "    for s in range(0, y.size, batch_size):\n",
    "        ids = perm[s : s + batch_size]\n",
    "        yield X[ids], y[ids]\n",
    "\n",
    "def loss_fn(model, X, y):\n",
    "    return nn.losses.cross_entropy(model(X), y, reduction=\"mean\")\n",
    "\n",
    "train_images, train_labels, test_images, test_labels = map(\n",
    "    mx.array, getattr(mnist, \"mnist\")()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Test Accuracy: 0.5331000089645386 Time: 1.028\n",
      "Epoch: 2, Test Accuracy: 0.8323999643325806 Time: 0.941\n",
      "Epoch: 3, Test Accuracy: 0.8858000040054321 Time: 0.913\n",
      "Epoch: 4, Test Accuracy: 0.9019999504089355 Time: 0.929\n",
      "Epoch: 5, Test Accuracy: 0.9106000065803528 Time: 0.937\n",
      "Epoch: 6, Test Accuracy: 0.9225999712944031 Time: 0.937\n",
      "Epoch: 7, Test Accuracy: 0.9325999617576599 Time: 0.941\n",
      "Epoch: 8, Test Accuracy: 0.9357999563217163 Time: 0.932\n",
      "Epoch: 9, Test Accuracy: 0.9402999877929688 Time: 0.935\n",
      "Epoch: 10, Test Accuracy: 0.9457999467849731 Time: 0.907\n"
     ]
    }
   ],
   "source": [
    "# create model\n",
    "model = MLP()\n",
    "# Set parameters\n",
    "mx.eval(model.parameters())\n",
    "\n",
    "# optim is from mlx.optimizers\n",
    "optimizer = optim.SGD(learning_rate=0.01)\n",
    "# nn is mlx.nn\n",
    "loss_and_grad_fn = nn.value_and_grad(model, loss_fn)\n",
    "\n",
    "@partial(mx.compile, inputs=model.state, outputs=model.state)\n",
    "def step(X, y):\n",
    "    loss, grads = loss_and_grad_fn(model, X, y)\n",
    "    optimizer.update(model, grads)\n",
    "    return loss\n",
    "\n",
    "@partial(mx.compile, inputs=model.state)\n",
    "def eval_fn(X, y):\n",
    "    return mx.mean(mx.argmax(model(X), axis=1) == y)\n",
    "\n",
    "\n",
    "for epoch in range(10):\n",
    "    tic = time.perf_counter()\n",
    "    train_loader = batch_iterate(64, train_images, train_labels)\n",
    "    for X, y in train_loader:\n",
    "        step(X, y)\n",
    "        mx.eval(model.state)\n",
    "    accuracy = eval_fn(test_images, test_labels)\n",
    "    toc = time.perf_counter()\n",
    "    print(\n",
    "        f\"Epoch: {epoch+1}, Test Accuracy: {accuracy}\",\n",
    "        f\"Time: {toc - tic:.3f}\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Test Accuracy: 0.49810001254081726 Time: 3.200\n",
      "Epoch: 2, Test Accuracy: 0.8302000164985657 Time: 3.153\n",
      "Epoch: 3, Test Accuracy: 0.8851000070571899 Time: 3.232\n",
      "Epoch: 4, Test Accuracy: 0.9004999995231628 Time: 3.211\n",
      "Epoch: 5, Test Accuracy: 0.9106000065803528 Time: 3.123\n",
      "Epoch: 6, Test Accuracy: 0.9247999787330627 Time: 3.130\n",
      "Epoch: 7, Test Accuracy: 0.9301000237464905 Time: 3.160\n",
      "Epoch: 8, Test Accuracy: 0.939300000667572 Time: 3.111\n",
      "Epoch: 9, Test Accuracy: 0.9438999891281128 Time: 3.109\n",
      "Epoch: 10, Test Accuracy: 0.9462000131607056 Time: 3.271\n"
     ]
    }
   ],
   "source": [
    "model = MLP()\n",
    "mx.eval(model.parameters())\n",
    "\n",
    "def loss_fn(model, X, y):\n",
    "    return nn.losses.cross_entropy(model(X), y, reduction=\"mean\")\n",
    "\n",
    "optimizer = optim.SGD(learning_rate=0.01)\n",
    "loss_and_grad_fn = nn.value_and_grad(model, loss_fn)\n",
    "\n",
    "@partial(mx.compile, inputs=model.state, outputs=model.state)\n",
    "def step(X, y):\n",
    "    loss, grads = loss_and_grad_fn(model, X, y)\n",
    "    optimizer.update(model, grads)\n",
    "    return loss\n",
    "\n",
    "@partial(mx.compile, inputs=model.state)\n",
    "def eval_fn(X, y):\n",
    "    return mx.mean(mx.argmax(model(X), axis=1) == y)\n",
    "\n",
    "\n",
    "_, train_loader = load_data(batch_size=64)\n",
    "_, test_loader = load_data(batch_size=64, train=False)\n",
    "\n",
    "for epoch in range(10):\n",
    "    tic = time.perf_counter()\n",
    "    for X, y in train_loader:\n",
    "        X, y = mx.array(X), mx.array(y)\n",
    "        X = X.flatten(start_axis=1)\n",
    "        step(X, y)\n",
    "        mx.eval(model.state)\n",
    "    \n",
    "    accuracy = 0\n",
    "    n = 0\n",
    "\n",
    "    for X, y in test_loader:\n",
    "        X, y = mx.array(X), mx.array(y)\n",
    "        X = X.flatten(start_axis=1)\n",
    "        accuracy += (model(X).argmax(axis=1) == y).sum()\n",
    "        n += len(y)\n",
    "\n",
    "    toc = time.perf_counter()\n",
    "    print(\n",
    "        f\"Epoch: {epoch+1}, Test Accuracy: {accuracy / n}\",\n",
    "        f\"Time: {toc - tic:.3f}\"\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sci",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
